{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1CXA-NDhm2s3-gPLx7e7GL6rdrGw2E1-m","authorship_tag":"ABX9TyOsB5hrRe3Bafz2Whg4bFHx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed9-Oj8zpKHP","executionInfo":{"status":"ok","timestamp":1719208715015,"user_tz":-540,"elapsed":10744,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"23c199c7-c8c3-4698-f8ec-b55b07241e01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","PATH = \"/content/drive/MyDrive/dataset/ch9/\"\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using {} device\".format(device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XgxZXDYtuDN","executionInfo":{"status":"ok","timestamp":1719223243187,"user_tz":-540,"elapsed":3116,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"f6247972-e947-4b02-9176-ead4e0f0f35c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"code","source":["# 80\n","import re\n","import collections\n","\n","# CATEGORYをencodeする\n","def Encoder(sign):\n","    if sign == \"b\":\n","      return 0\n","    elif sign == \"t\":\n","      return 1\n","    elif sign == \"e\":\n","      return 2\n","    elif sign == \"m\":\n","      return 3\n","\n","def Process(lines):\n","    sign_regrex = re.compile('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`|＄＃＠£â€™é\\n]')\n","    # 記号など削除する\n","    word_list = []\n","    text_list = []\n","    true_label = []\n","\n","    for text in lines:\n","\n","      # print(text)\n","\n","      true_label.append(text.split(\"\\t\")[3])\n","      # CATEGORYをもらう\n","      # print(true_label)\n","\n","      text = text.split(\"\\t\")[0]\n","      # titleの内容をもらう\n","      # print(text)\n","      text = sign_regrex.sub(\"\", text)\n","      # 記号など削除する\n","\n","      text = re.sub(\"(\\d+)\", r\" \\1 \", text)\n","      # 数字と単語の間にspaceを入れる\n","      # print(text)\n","\n","      words = text.split(\" \")\n","      # 単語をもらう\n","      words = list(filter(lambda x:x, words))\n","      #空リスト削除\n","      words = list(map(lambda x:x.lower(), words))\n","      #小文字にする\n","\n","      word_list.extend(words)\n","      text_list.append(words)\n","\n","    return word_list, text_list, true_label\n","\n","def MakeDict(name):\n","  # 辞書を作る\n","    f = open(PATH + \"{}.txt\".format(name), \"r\")\n","    lines = f.readlines()\n","    f.close()\n","    word_list, _, _ = Process(lines)\n","    c = collections.Counter(word_list).most_common()\n","    # 単語頻度の降順に並べ替え\n","    word_dic = {}\n","    for id, word in enumerate(c, 1):\n","      # 単語を、データセット中の単語頻度の降順に並べ替え、IDを単語頻度の順位に対応させる\n","      # 単語頻度が1のすべての単語について、そのIDを0にする。\n","        if int(word[1]) < 2:\n","            word_dic[word[0]] = 0\n","        else:\n","            word_dic[word[0]] = id\n","    return word_dic\n","\n","# trainに基づいて辞書を作る\n","word_dic = MakeDict(\"train\")\n","\n","def Word2Code(name, word_dic):\n","    f = open(PATH + \"{}.txt\".format(name), \"r\")\n","    lines = f.readlines()\n","    lines.pop(0)\n","    #カラムの行を除く\n","\n","    _, text_list, true_label = Process(lines)\n","\n","    true_label = list(map(Encoder, true_label))\n","    # true_label一行目ずつEncoder関数で処理する\n","\n","    result_list = []\n","\n","    # 単語をcodeにする\n","    for text in text_list:\n","        code_list = []\n","        for word in text:\n","            try:\n","                code = word_dic[word]\n","            except:\n","                code = 0\n","            code_list.append(code)\n","        result_list.append(code_list)\n","\n","\n","    # 処理したdataをfileに書き込んで保存する\n","    f = open(PATH + \"{}_code.txt\".format(name), \"w\")\n","    i = 0\n","    for t1, t2, t3 in zip(true_label, text_list, result_list):\n","      # 出力の形式を調整する\n","        if i==0:\n","            f.write(str(t1)+\"\\t\"+\" \".join(t2)+\"\\t\"+\" \".join(map(str, t3)))\n","            i = 1\n","        else:\n","            f.write(\"\\n\"+str(t1)+\"\\t\"+\" \".join(t2)+\"\\t\"+\" \".join(map(str, t3)))\n","    f.close()"],"metadata":{"id":"kGV4l0uQlO-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 80\n","\n","Word2Code(\"train\", word_dic)\n","Word2Code(\"test\", word_dic)\n","Word2Code(\"valid\", word_dic)"],"metadata":{"id":"BWDci_PKuFC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n","from torch.utils.data import DataLoader, TensorDataset"],"metadata":{"id":"TsbPNjHM3qJj","executionInfo":{"status":"ok","timestamp":1719223247033,"user_tz":-540,"elapsed":499,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# LSTMを定義する\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, dw, dh, output):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size, dw, padding_idx=vocab_size-1)\n","        # 入力したdataを300次元の単語ベクトルへ変更する\n","        self.lstm = nn.LSTM(dw, dh, batch_first=True)\n","        # LSTMを実現する\n","        self.fc1 = nn.Linear(dh, output, bias=True)\n","        # 300次元から４次元に変更する\n","        self.fc2 = nn.Softmax(dim=1)\n","        # Softmax関数を施す\n","\n","        # 重みを初期化する\n","        nn.init.xavier_normal_(self.lstm.weight_ih_l0)\n","        nn.init.xavier_normal_(self.lstm.weight_hh_l0)\n","        nn.init.xavier_normal_(self.fc1.weight)\n","\n","\n","    def forward(self, x):\n","        x = x.to(device)\n","        x = self.embed(x)\n","        x, _ = self.lstm(x)\n","        x = self.fc1(x[:, -1, :])\n","        x = self.fc2(x)\n","        return x\n","\n","\n","\n","def CountVocab(name):\n","    f = open(PATH + \"{}_code.txt\".format(name), \"r\")\n","    lines = f.readlines()\n","    f.close()\n","    max_num = []\n","    i = 0\n","    for line in lines:\n","      line_t = line.split(\"\\t\")[2].replace(\"\\n\", \"\").split(\" \")\n","      # 単語のIDをもらう\n","      max_num.extend(map(int, line_t))\n","\n","    vocab_max = max(max_num)+1\n","    # 最大のIDをもらう\n","    return vocab_max\n","\n","def GetCodeLow(name):\n","\n","    f = open(PATH + \"{}_code.txt\".format(name), \"r\")\n","    lines = f.readlines()\n","    f.close()\n","    num_list = []\n","    code_list = []\n","    pad_list = []\n","\n","    for line in lines:\n","\n","      try:\n","        line_s = line.split(\"\\t\")\n","        # print(line_s)\n","        code_list.append(int(line_s[0]))\n","        # print(code_list)\n","        # CATEGORYのcodeをもらう\n","        num = line_s[2].replace(\"\\n\", \"\").split(\" \")\n","        num = list(map(int, num))\n","        num_list.append(num)\n","        # 単語のcodeをもらう\n","        num_tensor = torch.tensor(num)\n","        # print(num_tensor)\n","        # codeをtensorへ変更する\n","        pad_list.append(num_tensor)\n","      except:\n","          pass\n","\n","    max_vocab = CountVocab(\"train\")\n","    # 最大code\n","    # print(max_vocab)\n","\n","\n","    # 计算每个序列的长度\n","    lengths = [len(seq) for seq in num_list]\n","    # print(lengths)\n","\n","    # 使用 pad_sequence 进行填充\n","    padded_sequences = pad_sequence(pad_list, batch_first=True, padding_value=max_vocab)\n","\n","    # # 使用 pack_padded_sequence 打包序列\n","    # packed_sequences = pack_padded_sequence(padded_sequences, lengths, batch_first=True, enforce_sorted=False)\n","\n","    code_list = torch.tensor(code_list)\n","    return padded_sequences, code_list\n","\n","\n","\n","\n","\n","\n","X_valid, Y_valid = GetCodeLow(\"valid\")\n","X_valid, Y_valid = X_valid.to(device), Y_valid.to(device)\n","# print(Y_valid)\n","\n","VOCAB_SIZE = CountVocab(\"train\")+1\n","EMB_SIZE = 300\n","OUTPUT_SIZE = 4\n","HIDDEN_SIZE = 50\n","\n","model = LSTM(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(device)\n","Y_pred = model(X_valid)\n","# print(Y_pred)\n","\n","# 获取预测标签\n","pred = torch.argmax(Y_pred, dim=-1)\n","# print(pred)\n","\n","# 正解率を計算する\n","accuracy = sum(1 for x, y in zip(Y_valid, pred) if x == y) / float(len(Y_pred))\n","print(\"accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NilT_sgQn3Pi","executionInfo":{"status":"ok","timestamp":1719208750310,"user_tz":-540,"elapsed":3517,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"8df44b12-8f24-4435-fa9d-b28e00e0f31f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy:  0.39280359820089955\n"]}]},{"cell_type":"code","source":["# 82\n","\n","X_train, y_train = GetCodeLow(\"train\")\n","# print(X_train.shape, y_train.shape)\n","\n","num_epochs = 50\n","batch_size = 64\n","lr = 5e-1\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# lossとSGDを定義する\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","# modelを訓練する\n","for epoch in range(num_epochs):\n","    model.train()\n","    for X_batch, y_batch in train_loader:\n","      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","      # 前向传播\n","      outputs = model(X_batch)\n","      loss = criterion(outputs, y_batch)\n","\n","      # 反向传播和优化\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# 評価する\n","model.eval()\n","with torch.no_grad():\n","    Y_pred = model(X_valid).to(device)\n","    pred = torch.argmax(Y_pred, dim=-1)\n","    accuracy = (Y_valid == pred).sum().item() / float(len(Y_pred))\n","    print(\"accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUTLWONHDYlt","executionInfo":{"status":"ok","timestamp":1719118733775,"user_tz":-540,"elapsed":16168,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"a85ecccf-2d5a-44fc-cf95-3ee346afd16a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Loss: 0.8475\n","Epoch [2/50], Loss: 0.7864\n","Epoch [3/50], Loss: 0.9505\n","Epoch [4/50], Loss: 0.8478\n","Epoch [5/50], Loss: 0.9103\n","Epoch [6/50], Loss: 0.8281\n","Epoch [7/50], Loss: 0.8471\n","Epoch [8/50], Loss: 0.8559\n","Epoch [9/50], Loss: 0.9209\n","Epoch [10/50], Loss: 0.9124\n","Epoch [11/50], Loss: 0.9088\n","Epoch [12/50], Loss: 0.9287\n","Epoch [13/50], Loss: 0.8875\n","Epoch [14/50], Loss: 0.8479\n","Epoch [15/50], Loss: 0.8449\n","Epoch [16/50], Loss: 0.9103\n","Epoch [17/50], Loss: 0.8899\n","Epoch [18/50], Loss: 0.9521\n","Epoch [19/50], Loss: 0.9418\n","Epoch [20/50], Loss: 0.8267\n","Epoch [21/50], Loss: 0.8452\n","Epoch [22/50], Loss: 0.9728\n","Epoch [23/50], Loss: 0.9727\n","Epoch [24/50], Loss: 0.9313\n","Epoch [25/50], Loss: 0.9103\n","Epoch [26/50], Loss: 0.9102\n","Epoch [27/50], Loss: 0.8896\n","Epoch [28/50], Loss: 0.8687\n","Epoch [29/50], Loss: 0.9543\n","Epoch [30/50], Loss: 0.9103\n","Epoch [31/50], Loss: 0.8270\n","Epoch [32/50], Loss: 0.9302\n","Epoch [33/50], Loss: 0.8463\n","Epoch [34/50], Loss: 0.9101\n","Epoch [35/50], Loss: 0.9509\n","Epoch [36/50], Loss: 0.9307\n","Epoch [37/50], Loss: 0.8270\n","Epoch [38/50], Loss: 0.8478\n","Epoch [39/50], Loss: 0.8062\n","Epoch [40/50], Loss: 0.8273\n","Epoch [41/50], Loss: 0.8487\n","Epoch [42/50], Loss: 0.9312\n","Epoch [43/50], Loss: 0.8272\n","Epoch [44/50], Loss: 0.8070\n","Epoch [45/50], Loss: 0.8464\n","Epoch [46/50], Loss: 0.9508\n","Epoch [47/50], Loss: 0.8900\n","Epoch [48/50], Loss: 0.8894\n","Epoch [49/50], Loss: 0.9103\n","Epoch [50/50], Loss: 0.8161\n","accuracy:  0.7338830584707646\n"]}]},{"cell_type":"code","source":["# 83\n","bs_list = [2**i for i in range(10)]\n","\n","for bs in bs_list:\n","  for epoch in range(num_epochs):\n","    model.train()\n","    for X_batch, y_batch in train_loader:\n","      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","      # 前向传播\n","      outputs = model(X_batch)\n","      loss = criterion(outputs, y_batch)\n","\n","      # 反向传播和优化\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","\n","  print(f'batch [{bs}], Loss: {loss.item():.4f}')\n","  # 評価する\n","  model.eval()\n","  with torch.no_grad():\n","    Y_pred = model(X_valid).to(device)\n","    pred = torch.argmax(Y_pred, dim=-1)\n","    accuracy = (Y_valid == pred).sum().item() / float(len(Y_pred))\n","    print(\"accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04pPuK5kfqih","executionInfo":{"status":"ok","timestamp":1719036099360,"user_tz":-540,"elapsed":187104,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"efaa6805-db62-45df-8d51-bc84ddfabbb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["batch [1], Loss: 0.7853\n","accuracy:  0.8335832083958021\n","batch [2], Loss: 0.8895\n","accuracy:  0.8328335832083958\n","batch [4], Loss: 0.8062\n","accuracy:  0.8328335832083958\n","batch [8], Loss: 0.7837\n","accuracy:  0.8320839580209896\n","batch [16], Loss: 0.7645\n","accuracy:  0.8320839580209896\n","batch [32], Loss: 0.7645\n","accuracy:  0.8328335832083958\n","batch [64], Loss: 0.8062\n","accuracy:  0.8328335832083958\n","batch [128], Loss: 0.7646\n","accuracy:  0.8133433283358321\n","batch [256], Loss: 0.7853\n","accuracy:  0.8110944527736131\n","batch [512], Loss: 0.8478\n","accuracy:  0.8110944527736131\n"]}]},{"cell_type":"code","source":["# 84\n","\n","from gensim.models import KeyedVectors\n","import numpy as np\n","\n","# 重み行列をもらう\n","\n","def GetInitWeight():\n","    vectors = KeyedVectors.load_word2vec_format(PATH + 'GoogleNews-vectors-negative300.bin', binary=True)\n","    # fileを読み込む\n","    worddic = MakeDict(\"train\")\n","    # 辞書を作る\n","\n","    # 重み行列を初期化する\n","    init_weight = []\n","    init_weight.append(list(np.zeros(300)))\n","\n","    # 各単語にベクトルを付ける\n","    for key, value in worddic.items():\n","      # print(key, value)\n","      if value == 0:\n","        continue\n","      else:\n","        try:\n","          init_weight.append(list(vectors[key]))\n","        except:\n","          init_weight.append(list(np.zeros(300)))\n","\n","    init_weight.append(list(np.zeros(300)))\n","    # listからtensorへ変更する\n","    weights = torch.tensor(init_weight)\n","    weights = weights.float()\n","    return weights\n","\n","weights = GetInitWeight()"],"metadata":{"id":"5LxV2N7PnCt1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 84\n","\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, dw, dh, output, init_weight=None):\n","        super().__init__()\n","\n","        # Embedding layerに重み行列を提供する\n","        # 入力したdataの次元から300へ変更する\n","        if init_weight != None:\n","          self.embed = nn.Embedding.from_pretrained(init_weight, padding_idx=vocab_size-1)\n","        else:\n","          self.embed = nn.Embedding(vocab_size, dw, padding_idx=vocab_size-1)\n","\n","        self.lstm = nn.LSTM(dw, dh, batch_first=True, bidirectional=True)\n","        # LSTMを実現する\n","        self.fc1 = nn.Linear(dh, output, bias=True)\n","        # 300次元から４次元に変更する\n","\n","        self.fc2 = nn.Softmax(dim=1)\n","        # Softmax関数を施す\n","\n","        # 重みを初期化する\n","        nn.init.xavier_normal_(self.lstm.weight_ih_l0)\n","        nn.init.xavier_normal_(self.lstm.weight_hh_l0)\n","        nn.init.xavier_normal_(self.fc1.weight)\n","\n","\n","    def forward(self, x):\n","        x = x.to(device)\n","        x = self.embed(x)\n","        x, _ = self.lstm(x)\n","        x = self.fc1(x[:, -1, :])\n","        x = self.fc2(x)\n","        return x\n","\n","X_train, y_train = GetCodeLow(\"train\")\n","# print(X_train.shape, y_train.shape)\n","X_test, y_test = GetCodeLow(\"test\")\n","X_test, y_test = X_test.to(device), y_test.to(device)\n","# print(X_test.shape, y_test.shape)\n","\n","num_epochs = 100\n","batch_size = 64\n","lr = 5e-1\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","train_dataset = TensorDataset(X_test, y_test)\n","test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# lossとSGDを定義する\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","model = LSTM(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, weights).to(device)\n","\n","# modelを訓練する\n","for epoch in range(num_epochs):\n","    model.train()\n","    for X_batch, y_batch in train_loader:\n","      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","      # 前向传播\n","      outputs = model(X_batch)\n","      loss = criterion(outputs, y_batch)\n","\n","      # 反向传播和优化\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# 評価する\n","model.eval()\n","with torch.no_grad():\n","    Y_pred = model(X_test).to(device)\n","    pred = torch.argmax(Y_pred, dim=-1)\n","    accuracy = (y_test == pred).sum().item() / float(len(Y_pred))\n","    print(\"accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3jryK18yisRu","executionInfo":{"status":"ok","timestamp":1719120911445,"user_tz":-540,"elapsed":41988,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"ca60e903-ca5e-43e0-97de-1298c7236bdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100], Loss: 1.2617\n","Epoch [2/100], Loss: 1.2513\n","Epoch [3/100], Loss: 1.2906\n","Epoch [4/100], Loss: 1.2742\n","Epoch [5/100], Loss: 1.2250\n","Epoch [6/100], Loss: 1.2968\n","Epoch [7/100], Loss: 1.3092\n","Epoch [8/100], Loss: 1.2575\n","Epoch [9/100], Loss: 1.2883\n","Epoch [10/100], Loss: 1.2421\n","Epoch [11/100], Loss: 1.0799\n","Epoch [12/100], Loss: 1.2509\n","Epoch [13/100], Loss: 1.2510\n","Epoch [14/100], Loss: 1.2517\n","Epoch [15/100], Loss: 1.2660\n","Epoch [16/100], Loss: 1.2486\n","Epoch [17/100], Loss: 1.2726\n","Epoch [18/100], Loss: 1.2577\n","Epoch [19/100], Loss: 1.3382\n","Epoch [20/100], Loss: 0.9755\n","Epoch [21/100], Loss: 0.9332\n","Epoch [22/100], Loss: 0.9582\n","Epoch [23/100], Loss: 1.0532\n","Epoch [24/100], Loss: 1.0146\n","Epoch [25/100], Loss: 0.9100\n","Epoch [26/100], Loss: 0.9421\n","Epoch [27/100], Loss: 0.9917\n","Epoch [28/100], Loss: 0.9382\n","Epoch [29/100], Loss: 0.9688\n","Epoch [30/100], Loss: 1.0541\n","Epoch [31/100], Loss: 0.8657\n","Epoch [32/100], Loss: 0.9440\n","Epoch [33/100], Loss: 0.9170\n","Epoch [34/100], Loss: 0.8915\n","Epoch [35/100], Loss: 1.0002\n","Epoch [36/100], Loss: 1.0072\n","Epoch [37/100], Loss: 1.0596\n","Epoch [38/100], Loss: 1.0121\n","Epoch [39/100], Loss: 0.9791\n","Epoch [40/100], Loss: 0.9439\n","Epoch [41/100], Loss: 0.9977\n","Epoch [42/100], Loss: 1.0208\n","Epoch [43/100], Loss: 0.9031\n","Epoch [44/100], Loss: 0.9280\n","Epoch [45/100], Loss: 0.9764\n","Epoch [46/100], Loss: 0.9722\n","Epoch [47/100], Loss: 0.9089\n","Epoch [48/100], Loss: 0.9360\n","Epoch [49/100], Loss: 0.9231\n","Epoch [50/100], Loss: 0.9245\n","Epoch [51/100], Loss: 0.9648\n","Epoch [52/100], Loss: 0.9631\n","Epoch [53/100], Loss: 1.0562\n","Epoch [54/100], Loss: 0.8671\n","Epoch [55/100], Loss: 0.8449\n","Epoch [56/100], Loss: 0.8846\n","Epoch [57/100], Loss: 0.9508\n","Epoch [58/100], Loss: 0.9652\n","Epoch [59/100], Loss: 0.8077\n","Epoch [60/100], Loss: 0.9290\n","Epoch [61/100], Loss: 0.7678\n","Epoch [62/100], Loss: 0.8491\n","Epoch [63/100], Loss: 0.9061\n","Epoch [64/100], Loss: 0.8559\n","Epoch [65/100], Loss: 0.8475\n","Epoch [66/100], Loss: 0.8413\n","Epoch [67/100], Loss: 0.8994\n","Epoch [68/100], Loss: 0.8371\n","Epoch [69/100], Loss: 0.7850\n","Epoch [70/100], Loss: 0.8487\n","Epoch [71/100], Loss: 0.8544\n","Epoch [72/100], Loss: 0.9094\n","Epoch [73/100], Loss: 0.8253\n","Epoch [74/100], Loss: 0.8072\n","Epoch [75/100], Loss: 0.8733\n","Epoch [76/100], Loss: 0.8304\n","Epoch [77/100], Loss: 0.8626\n","Epoch [78/100], Loss: 0.8701\n","Epoch [79/100], Loss: 0.8074\n","Epoch [80/100], Loss: 0.8741\n","Epoch [81/100], Loss: 0.8261\n","Epoch [82/100], Loss: 0.8279\n","Epoch [83/100], Loss: 0.8063\n","Epoch [84/100], Loss: 0.8125\n","Epoch [85/100], Loss: 0.7661\n","Epoch [86/100], Loss: 0.7647\n","Epoch [87/100], Loss: 0.7770\n","Epoch [88/100], Loss: 0.8267\n","Epoch [89/100], Loss: 0.8892\n","Epoch [90/100], Loss: 0.8063\n","Epoch [91/100], Loss: 0.8735\n","Epoch [92/100], Loss: 0.8481\n","Epoch [93/100], Loss: 0.8031\n","Epoch [94/100], Loss: 0.8087\n","Epoch [95/100], Loss: 0.8279\n","Epoch [96/100], Loss: 0.8620\n","Epoch [97/100], Loss: 0.8263\n","Epoch [98/100], Loss: 0.8099\n","Epoch [99/100], Loss: 0.8150\n","Epoch [100/100], Loss: 0.8491\n","accuracy:  0.8853073463268366\n"]}]},{"cell_type":"code","source":["# 85\n","\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, dw, dh, output, num_layers=5):\n","        super().__init__()\n","\n","        self.embed = nn.Embedding(vocab_size, dw, padding_idx=vocab_size-1)\n","        # 入力したdataの次元から300へ変更する\n","\n","        self.lstm = nn.LSTM(dw, dh, num_layers=num_layers, batch_first=True)\n","        # LSTMを実現する\n","\n","        self.fc1 = nn.Linear(dh, output, bias=True)\n","        # 300次元から4次元に変更する\n","\n","        self.fc2 = nn.Softmax(dim=1)\n","        # Softmax関数を施す\n","\n","        # hidden state と cell stateをLSTMに初期化する\n","        for name, param in self.lstm.named_parameters():\n","            if 'weight_ih' in name or 'weight_hh' in name:\n","                nn.init.xavier_normal_(param)\n","\n","        nn.init.xavier_normal_(self.fc1.weight)\n","\n","\n","    def forward(self, x):\n","        x = x.to(device)\n","        x = self.embed(x)\n","\n","        # hidden state と cell state ゼロになる\n","        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(device)\n","        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(device)\n","\n","\n","        x, _ = self.lstm(x, (h0, c0))\n","\n","\n","        x = self.fc1(x[:, -1, :])\n","        x = self.fc2(x)\n","\n","        return x\n","\n","X_train, y_train = GetCodeLow(\"train\")\n","# print(X_train.shape, y_train.shape)\n","X_test, y_test = GetCodeLow(\"test\")\n","X_test, y_test = X_test.to(device), y_test.to(device)\n","# print(X_test.shape, y_test.shape)\n","\n","num_epochs = 50\n","batch_size = 64\n","lr = 5e-1\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","train_dataset = TensorDataset(X_test, y_test)\n","test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# lossとSGDを定義する\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","model = LSTM(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(device)\n","\n","# modelを訓練する\n","for epoch in range(num_epochs):\n","    model.train()\n","    for X_batch, y_batch in train_loader:\n","      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","      # 前向传播\n","      outputs = model(X_batch)\n","      loss = criterion(outputs, y_batch)\n","\n","      # 反向传播和优化\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# 評価する\n","model.eval()\n","with torch.no_grad():\n","    Y_pred = model(X_test).to(device)\n","    pred = torch.argmax(Y_pred, dim=-1)\n","    accuracy = (y_test == pred).sum().item() / float(len(Y_pred))\n","    print(\"accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hnud0DU5nlwB","executionInfo":{"status":"ok","timestamp":1719120953213,"user_tz":-540,"elapsed":21289,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"0d9eadbd-a963-4cb4-bb20-837c4f3ad8c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Loss: 0.8386\n","Epoch [2/50], Loss: 0.7997\n","Epoch [3/50], Loss: 0.8470\n","Epoch [4/50], Loss: 0.8270\n","Epoch [5/50], Loss: 0.7437\n","Epoch [6/50], Loss: 0.8519\n","Epoch [7/50], Loss: 0.8063\n","Epoch [8/50], Loss: 0.7636\n","Epoch [9/50], Loss: 0.8251\n","Epoch [10/50], Loss: 0.8273\n","Epoch [11/50], Loss: 0.8062\n","Epoch [12/50], Loss: 0.7884\n","Epoch [13/50], Loss: 0.8058\n","Epoch [14/50], Loss: 0.8074\n","Epoch [15/50], Loss: 0.8155\n","Epoch [16/50], Loss: 0.7646\n","Epoch [17/50], Loss: 0.7445\n","Epoch [18/50], Loss: 0.8265\n","Epoch [19/50], Loss: 0.7844\n","Epoch [20/50], Loss: 0.8348\n","Epoch [21/50], Loss: 0.7649\n","Epoch [22/50], Loss: 0.8689\n","Epoch [23/50], Loss: 0.8475\n","Epoch [24/50], Loss: 0.8063\n","Epoch [25/50], Loss: 0.8132\n","Epoch [26/50], Loss: 0.8145\n","Epoch [27/50], Loss: 0.8271\n","Epoch [28/50], Loss: 0.8309\n","Epoch [29/50], Loss: 0.8073\n","Epoch [30/50], Loss: 0.7670\n","Epoch [31/50], Loss: 0.8686\n","Epoch [32/50], Loss: 0.8884\n","Epoch [33/50], Loss: 0.7759\n","Epoch [34/50], Loss: 0.7875\n","Epoch [35/50], Loss: 0.7658\n","Epoch [36/50], Loss: 0.8115\n","Epoch [37/50], Loss: 0.8064\n","Epoch [38/50], Loss: 0.8271\n","Epoch [39/50], Loss: 0.7647\n","Epoch [40/50], Loss: 0.8261\n","Epoch [41/50], Loss: 0.7854\n","Epoch [42/50], Loss: 0.7856\n","Epoch [43/50], Loss: 0.7645\n","Epoch [44/50], Loss: 0.7648\n","Epoch [45/50], Loss: 0.7645\n","Epoch [46/50], Loss: 0.8073\n","Epoch [47/50], Loss: 0.8271\n","Epoch [48/50], Loss: 0.8222\n","Epoch [49/50], Loss: 0.7853\n","Epoch [50/50], Loss: 0.8062\n","accuracy:  0.8928035982008995\n"]}]},{"cell_type":"code","source":["# 86\n","\n","import torch.nn.functional as F\n","\n","class CNN(nn.Module):\n","  def __init__(self, vocab_size, dw, dh, output):\n","      super().__init__()\n","      self.embed = nn.Embedding(vocab_size, dw, padding_idx=vocab_size-1)\n","      # 入力したdataを300次元の単語ベクトルへ変更する\n","\n","      self.conv1 = nn.Conv2d(1, 3, kernel_size=(3, 300))\n","      # 畳み込みのストライド: 1 トークン\n","      # 畳み込みのフィルターのサイズ: 3 トークン\n","      # kernel_sizeのサイズは(3, 300)\n","\n","\n","      self.tanh = nn.ReLU()\n","      # 活性化関数ReLUを施す\n","\n","      self.fc1 = nn.Linear(3, output, bias=True)\n","      # 3次元->4次元\n","\n","      self.fc2 = nn.Softmax(dim=1)\n","      # Softmax関数を施す\n","\n","  def forward(self, x):\n","      x = self.embed(x)\n","      x = x.unsqueeze(1)\n","      x = self.conv1(x)\n","      x = self.tanh(x)\n","      x = F.max_pool2d(x, kernel_size=(x.size()[2], 1))\n","      # 畳み込み層の出力に対する最大値プーリング\n","\n","      x = x.view(-1, 3)\n","      x = self.fc1(x)\n","      x = self.fc2(x)\n","      return x\n","\n","\n","X_valid, Y_valid = GetCodeLow(\"valid\")\n","X_valid, Y_valid = X_valid.to(device), Y_valid.to(device)\n","# print(Y_valid)\n","\n","VOCAB_SIZE = CountVocab(\"train\")+1\n","EMB_SIZE = 300\n","OUTPUT_SIZE = 4\n","HIDDEN_SIZE = 50\n","\n","model = CNN(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(device)\n","Y_pred = model(X_valid)\n","# print(Y_pred)\n","\n","# 获取预测标签\n","pred = torch.argmax(Y_pred, dim=-1)\n","# print(pred)\n","\n","# 正解率を計算する\n","accuracy = sum(1 for x, y in zip(Y_valid, pred) if x == y) / float(len(Y_pred))\n","print(\"accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wwmc6UCRhS5u","executionInfo":{"status":"ok","timestamp":1719118587201,"user_tz":-540,"elapsed":730,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"da4adbcf-453d-4e73-f7d0-689fd09d3dc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy:  0.11469265367316342\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]}]},{"cell_type":"code","source":["# 87\n","\n","X_train, y_train = GetCodeLow(\"train\")\n","# print(X_train.shape, y_train.shape)\n","X_test, y_test = GetCodeLow(\"test\")\n","X_test, y_test = X_test.to(device), y_test.to(device)\n","# print(X_test.shape, y_test.shape)\n","\n","num_epochs = 50\n","batch_size = 64\n","lr = 5e-1\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","train_dataset = TensorDataset(X_test, y_test)\n","test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# lossとSGDを定義する\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","# modelを訓練する\n","for epoch in range(num_epochs):\n","    model.train()\n","    for X_batch, y_batch in train_loader:\n","      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","      # 前向传播\n","      outputs = model(X_batch)\n","      loss = criterion(outputs, y_batch)\n","\n","      # 反向传播和优化\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# 評価する\n","model.eval()\n","with torch.no_grad():\n","    Y_pred = model(X_test).to(device)\n","    pred = torch.argmax(Y_pred, dim=-1)\n","    accuracy = (y_test == pred).sum().item() / float(len(Y_pred))\n","    print(\"accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pKtnRnWl23b","executionInfo":{"status":"ok","timestamp":1719118617749,"user_tz":-540,"elapsed":18807,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"d8e3b934-6a59-480a-c658-62443dd76f0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Loss: 0.9786\n","Epoch [2/50], Loss: 1.0566\n","Epoch [3/50], Loss: 1.0134\n","Epoch [4/50], Loss: 0.9410\n","Epoch [5/50], Loss: 1.0573\n","Epoch [6/50], Loss: 0.9548\n","Epoch [7/50], Loss: 1.0312\n","Epoch [8/50], Loss: 0.8907\n","Epoch [9/50], Loss: 1.0506\n","Epoch [10/50], Loss: 1.0337\n","Epoch [11/50], Loss: 0.9309\n","Epoch [12/50], Loss: 1.0137\n","Epoch [13/50], Loss: 0.9881\n","Epoch [14/50], Loss: 0.9128\n","Epoch [15/50], Loss: 0.9482\n","Epoch [16/50], Loss: 0.9096\n","Epoch [17/50], Loss: 0.9913\n","Epoch [18/50], Loss: 0.9927\n","Epoch [19/50], Loss: 0.9729\n","Epoch [20/50], Loss: 1.0335\n","Epoch [21/50], Loss: 0.8683\n","Epoch [22/50], Loss: 0.9616\n","Epoch [23/50], Loss: 0.9692\n","Epoch [24/50], Loss: 0.8871\n","Epoch [25/50], Loss: 0.9072\n","Epoch [26/50], Loss: 0.8465\n","Epoch [27/50], Loss: 1.0322\n","Epoch [28/50], Loss: 0.8887\n","Epoch [29/50], Loss: 0.9689\n","Epoch [30/50], Loss: 0.9937\n","Epoch [31/50], Loss: 1.0116\n","Epoch [32/50], Loss: 0.9488\n","Epoch [33/50], Loss: 1.0515\n","Epoch [34/50], Loss: 0.9313\n","Epoch [35/50], Loss: 0.9104\n","Epoch [36/50], Loss: 0.9088\n","Epoch [37/50], Loss: 0.9282\n","Epoch [38/50], Loss: 0.9669\n","Epoch [39/50], Loss: 1.0068\n","Epoch [40/50], Loss: 0.8960\n","Epoch [41/50], Loss: 1.0408\n","Epoch [42/50], Loss: 1.0180\n","Epoch [43/50], Loss: 0.9049\n","Epoch [44/50], Loss: 0.9285\n","Epoch [45/50], Loss: 0.9350\n","Epoch [46/50], Loss: 0.9135\n","Epoch [47/50], Loss: 0.8770\n","Epoch [48/50], Loss: 0.9509\n","Epoch [49/50], Loss: 0.9710\n","Epoch [50/50], Loss: 0.8938\n","accuracy:  0.719640179910045\n"]}]},{"cell_type":"code","source":["%%bash\n","pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUROgoTUdM3v","executionInfo":{"status":"ok","timestamp":1719208807141,"user_tz":-540,"elapsed":6684,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"9b9bba95-f253-4fdb-c06e-9e6f801f63f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 380.1/380.1 kB 6.3 MB/s eta 0:00:00\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.4/233.4 kB 29.6 MB/s eta 0:00:00\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.6/78.6 kB 14.0 MB/s eta 0:00:00\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","Installing collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"]}]},{"cell_type":"code","source":["# 88\n","\n","# LSTMを定義する\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, dw, dh, output):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size, dw, padding_idx=vocab_size-1)\n","        # 入力したdataを300次元の単語ベクトルへ変更する\n","        self.lstm = nn.LSTM(dw, dh, batch_first=True)\n","        # LSTMを実現する\n","        self.fc1 = nn.Linear(dh, output, bias=True)\n","        # 300次元から４次元に変更する\n","        self.fc2 = nn.Softmax(dim=1)\n","        # Softmax関数を施す\n","\n","        # 重みを初期化する\n","        nn.init.xavier_normal_(self.lstm.weight_ih_l0)\n","        nn.init.xavier_normal_(self.lstm.weight_hh_l0)\n","        nn.init.xavier_normal_(self.fc1.weight)\n","\n","\n","    def forward(self, x):\n","        x = x.to(device)\n","        x = self.embed(x)\n","        x, _ = self.lstm(x)\n","        x = self.fc1(x[:, -1, :])\n","        x = self.fc2(x)\n","        return x\n","# CNNを定義する\n","class CNN(nn.Module):\n","  def __init__(self, vocab_size, dw, output, layer, unit, activation):\n","      super().__init__()\n","      self.layer = layer\n","      self.embed = nn.Embedding(vocab_size, dw, padding_idx = vocab_size-1)\n","\n","      # unit と　layerによって異なる畳み込みlayerを設定する\n","      if unit == 6:\n","          units = [6, 4, 2]\n","      elif unit == 4:\n","          units = [4, 3, 2]\n","      elif unit == 2:\n","          units = [2, 2, 2]\n","      self.conv1 = nn.Conv2d(1, units[0], kernel_size=(units[0], 300))\n","      linearoutput = units[0]\n","      if layer > 1:\n","          self.conv2 = nn.Conv2d(units[0], units[1], kernel_size=(units[1],1))\n","          linearoutput = units[1]\n","      if layer > 2:\n","          self.conv3 = nn.Conv2d(units[1], units[2], kernel_size=(units[2],1))\n","          linearoutput = units[2]\n","\n","\n","      self.fc1 = nn.Linear(linearoutput, output, bias=True)\n","      self.fc2 = nn.Softmax(dim=1)\n","\n","\n","      # 活性化関数を選ぶ\n","      if activation == \"Tanh\":\n","          self.active = nn.Tanh()\n","      elif activation == \"ReLU\":\n","          self.active = nn.ReLU()\n","      elif activation == \"Sigmoid\":\n","          self.active = nn.Sigmoid()\n","\n","\n","  def forward(self, x):\n","      x = self.embed(x)\n","      x = x.unsqueeze(1)\n","      x = self.conv1(x)\n","      x = self.active(x)\n","      if self.layer > 1:\n","          x = self.conv2(x)\n","          x = self.active(x)\n","      if self.layer > 2:\n","          x = self.conv3(x)\n","          x = self.active(x)\n","      x = F.max_pool2d(x, kernel_size=(x.size()[2], 1))\n","      x = x.view(x.size()[0], -1)\n","      x = self.fc1(x)\n","      x = self.fc2(x)\n","      return x\n","\n","# modelを訓練する\n","def train_model(X_train, y_train, X_test, y_test, batch_size, model, lr, num_epochs, device, collate_fn=None, optimizer_select=\"SGD\"):\n","    dataset_train = TensorDataset(X_train, y_train)\n","    dataset_test = TensorDataset(X_test, y_test)\n","    model = model.to(device)\n","    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n","    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n","    criterion = nn.CrossEntropyLoss()\n","    criterion = criterion.to(device)\n","\n","    for ep in range(num_epochs):\n","        if ep%20==0:\n","            lr = lr * 0.1\n","\n","        # optimizerを選ぶ\n","        if optimizer_select == \"SGD\":\n","            optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","        elif optimizer_select == \"Adam\":\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","        elif optimizer_select == \"RMSprop\":\n","          optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n","\n","        model.train()\n","        for X, Y in dataloader_train:\n","            X = X.to(device)\n","            Y = Y.to(device)\n","            optimizer.zero_grad()\n","            Y_pred = model(X)\n","            loss = criterion(Y_pred, Y)\n","            loss.backward()\n","            optimizer.step()\n","    model.eval()\n","    _, acc_test = calculate_loss_and_accuracy(model, dataset_test, device, criterion=criterion)\n","\n","    return acc_test\n","\n","# loss と　正解率を計算する\n","def calculate_loss_and_accuracy(model, dataset, device, criterion=None):\n","    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n","    loss = 0.0\n","    total = 0\n","    correct = 0\n","    model = model.to(device)\n","    with torch.no_grad():\n","        for X, Y in dataloader:\n","            X = X.to(device)\n","            Y = Y.to(device)\n","            Y_pred = model(X)\n","            if criterion != None:\n","                loss += criterion(Y_pred, Y).item()\n","            pred = torch.argmax(Y_pred, dim=-1)\n","            total += len(Y)\n","            correct += (pred == Y).sum().item()\n","    return loss / len(dataset), correct / total"],"metadata":{"id":"BXYOUR4zmDjT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective_LSTM(trial):\n","\n","    # dataを読み込む\n","    X_train, Y_train = GetCodeLow(\"train\")\n","    X_test, Y_test = GetCodeLow(\"test\")\n","\n","    # ハイパーパラメータを設定する\n","    BATCH_SIZE = 2\n","    NUM_EPOCHS = 10\n","    VOCAB_SIZE = CountVocab(\"train\")+1\n","    EMB_SIZE = 300\n","    OUTPUT_SIZE = 4\n","    lr = 1e-2\n","\n","    # Optuna を利用する\n","    model_name_display_only = trial.suggest_categorical(\"model_name_LSTM\", [\"LSTM\"])\n","    HIDDEN_SIZE = trial.suggest_categorical(\"HIDDEN_SIZE\", [10, 50, 100, 500])\n","    optimizer_select = trial.suggest_categorical(\"optimizer_select\", [\"SGD\", \"Adam\", \"RMSprop\"])\n","\n","    model = LSTM(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n","    score = train_model(X_train, Y_train, X_test, Y_test, BATCH_SIZE, model, lr, NUM_EPOCHS, device, optimizer_select)\n","    return score\n","\n","def objective_CNN(trial):\n","\n","    # dataを読み込む\n","    X_train, Y_train = GetCodeLow(\"train\")\n","    X_test, Y_test = GetCodeLow(\"test\")\n","\n","    # ハイパーパラメータを設定する\n","    BATCH_SIZE = 2\n","    NUM_EPOCHS = 10\n","    VOCAB_SIZE = CountVocab(\"train\")+1\n","    EMB_SIZE = 300\n","    OUTPUT_SIZE = 4\n","    lr = 1e-2\n","\n","    # Optuna を利用する\n","    model_name_display_only = trial.suggest_categorical(\"model_name_CNN\", [\"CNN\"])\n","    layer = trial.suggest_categorical(\"layer\", [1,2,3])\n","    unit = trial.suggest_categorical(\"unit\", [2,4,6])\n","    activation = trial.suggest_categorical(\"activation\", [\"Tanh\", \"Sigmoid\", \"ReLU\"])\n","    optimizer_select = trial.suggest_categorical(\"optimizer_select\", [\"SGD\", \"Adam\", \"RMSprop\"])\n","\n","\n","    model = CNN(VOCAB_SIZE, EMB_SIZE, OUTPUT_SIZE, layer, unit, activation)\n","    score = train_model(X_train, Y_train, X_test, Y_test, BATCH_SIZE, model, lr, NUM_EPOCHS, device, optimizer_select)\n","    return score"],"metadata":{"id":"hDXRmOCGnKUR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import optuna\n","import torch.nn.functional as F\n","\n","study = optuna.create_study(direction='maximize')\n","\n","study.optimize(objective_CNN, n_trials=81)\n","study.optimize(objective_LSTM, n_trials=15)\n","\n","print(study.best_params)\n","print(study.best_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VSetDHIodg5","executionInfo":{"status":"ok","timestamp":1719137444012,"user_tz":-540,"elapsed":8430824,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"0fd71646-4000-41e7-db0a-7db7e95113f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-06-23 07:50:12,257] A new study created in memory with name: no-name-d70107df-c36b-4942-ad4b-b7f00a1bf91c\n","[I 2024-06-23 07:51:53,037] Trial 0 finished with value: 0.6611694152923538 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 2, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 0 with value: 0.6611694152923538.\n","[I 2024-06-23 07:53:36,770] Trial 1 finished with value: 0.643928035982009 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'SGD'}. Best is trial 0 with value: 0.6611694152923538.\n","[I 2024-06-23 07:55:17,340] Trial 2 finished with value: 0.4325337331334333 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 4, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 0 with value: 0.6611694152923538.\n","[I 2024-06-23 07:56:35,306] Trial 3 finished with value: 0.6574212893553223 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 0 with value: 0.6611694152923538.\n","[I 2024-06-23 07:58:07,517] Trial 4 finished with value: 0.691904047976012 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'SGD'}. Best is trial 4 with value: 0.691904047976012.\n","[I 2024-06-23 07:59:34,522] Trial 5 finished with value: 0.4325337331334333 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 2, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 4 with value: 0.691904047976012.\n","[I 2024-06-23 08:00:52,935] Trial 6 finished with value: 0.704647676161919 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 6 with value: 0.704647676161919.\n","[I 2024-06-23 08:02:09,163] Trial 7 finished with value: 0.664167916041979 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 6 with value: 0.704647676161919.\n","[I 2024-06-23 08:03:26,462] Trial 8 finished with value: 0.6926536731634183 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 6 with value: 0.704647676161919.\n","[I 2024-06-23 08:04:43,923] Trial 9 finished with value: 0.6814092953523239 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 6 with value: 0.704647676161919.\n","[I 2024-06-23 08:06:01,713] Trial 10 finished with value: 0.6836581709145427 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 6 with value: 0.704647676161919.\n","[I 2024-06-23 08:07:17,990] Trial 11 finished with value: 0.7076461769115442 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 11 with value: 0.7076461769115442.\n","[I 2024-06-23 08:08:35,072] Trial 12 finished with value: 0.7031484257871065 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 11 with value: 0.7076461769115442.\n","[I 2024-06-23 08:09:51,859] Trial 13 finished with value: 0.6859070464767616 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 11 with value: 0.7076461769115442.\n","[I 2024-06-23 08:11:09,735] Trial 14 finished with value: 0.7151424287856072 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:12:38,547] Trial 15 finished with value: 0.6836581709145427 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'SGD'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:13:55,911] Trial 16 finished with value: 0.6634182908545727 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:15:13,618] Trial 17 finished with value: 0.6761619190404797 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:16:56,096] Trial 18 finished with value: 0.6626686656671664 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'SGD'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:18:25,083] Trial 19 finished with value: 0.4325337331334333 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 4, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:19:42,958] Trial 20 finished with value: 0.6881559220389805 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:21:00,376] Trial 21 finished with value: 0.712143928035982 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:22:17,622] Trial 22 finished with value: 0.7016491754122939 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:23:35,764] Trial 23 finished with value: 0.6806596701649176 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:24:53,181] Trial 24 finished with value: 0.6784107946026986 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 14 with value: 0.7151424287856072.\n","[I 2024-06-23 08:26:14,573] Trial 25 finished with value: 0.724887556221889 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:27:35,857] Trial 26 finished with value: 0.7188905547226386 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:28:57,421] Trial 27 finished with value: 0.684407796101949 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:30:41,197] Trial 28 finished with value: 0.6656671664167916 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'Adam'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:32:12,533] Trial 29 finished with value: 0.4325337331334333 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'Sigmoid', 'optimizer_select': 'SGD'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:33:32,897] Trial 30 finished with value: 0.7143928035982009 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:34:53,107] Trial 31 finished with value: 0.7143928035982009 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:36:13,978] Trial 32 finished with value: 0.7053973013493253 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:37:57,046] Trial 33 finished with value: 0.5022488755622189 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:39:17,598] Trial 34 finished with value: 0.704647676161919 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:41:01,130] Trial 35 finished with value: 0.6829085457271364 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:42:21,911] Trial 36 finished with value: 0.712143928035982 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'SGD'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:43:42,407] Trial 37 finished with value: 0.6829085457271364 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:45:14,695] Trial 38 finished with value: 0.684407796101949 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:46:35,424] Trial 39 finished with value: 0.7113943028485757 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:48:14,475] Trial 40 finished with value: 0.6656671664167916 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 2, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:49:35,361] Trial 41 finished with value: 0.7098950524737632 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:50:55,751] Trial 42 finished with value: 0.704647676161919 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:52:16,811] Trial 43 finished with value: 0.7128935532233883 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:53:37,473] Trial 44 finished with value: 0.7151424287856072 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:54:58,272] Trial 45 finished with value: 0.7106446776611695 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:56:15,206] Trial 46 finished with value: 0.6079460269865068 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:57:36,087] Trial 47 finished with value: 0.6821589205397302 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'SGD'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 08:58:56,861] Trial 48 finished with value: 0.7068965517241379 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:00:26,364] Trial 49 finished with value: 0.6176911544227887 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 2, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:01:47,354] Trial 50 finished with value: 0.6851574212893553 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:03:08,690] Trial 51 finished with value: 0.6979010494752623 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:04:29,274] Trial 52 finished with value: 0.7166416791604198 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:05:50,025] Trial 53 finished with value: 0.7166416791604198 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:07:11,405] Trial 54 finished with value: 0.7068965517241379 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'ReLU', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:08:31,848] Trial 55 finished with value: 0.7166416791604198 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:09:52,170] Trial 56 finished with value: 0.7113943028485757 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:11:08,569] Trial 57 finished with value: 0.7106446776611695 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 2, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:12:28,792] Trial 58 finished with value: 0.717391304347826 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:13:49,270] Trial 59 finished with value: 0.7008995502248876 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'SGD'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:15:21,166] Trial 60 finished with value: 0.6701649175412294 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:16:41,843] Trial 61 finished with value: 0.697151424287856 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:17:59,113] Trial 62 finished with value: 0.6784107946026986 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:19:19,410] Trial 63 finished with value: 0.7091454272863568 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:20:40,243] Trial 64 finished with value: 0.7151424287856072 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:21:58,159] Trial 65 finished with value: 0.6904047976011994 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:23:41,353] Trial 66 finished with value: 0.6806596701649176 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:25:02,603] Trial 67 finished with value: 0.6964017991004497 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Sigmoid', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:26:19,973] Trial 68 finished with value: 0.6881559220389805 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 4, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:27:41,478] Trial 69 finished with value: 0.7128935532233883 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'RMSprop'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:29:02,485] Trial 70 finished with value: 0.717391304347826 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:30:23,412] Trial 71 finished with value: 0.6986506746626686 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:31:43,990] Trial 72 finished with value: 0.7061469265367316 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:33:04,141] Trial 73 finished with value: 0.7106446776611695 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 25 with value: 0.724887556221889.\n","[I 2024-06-23 09:34:24,361] Trial 74 finished with value: 0.7263868065967016 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:35:44,259] Trial 75 finished with value: 0.691904047976012 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:37:04,790] Trial 76 finished with value: 0.719640179910045 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:38:35,875] Trial 77 finished with value: 0.4325337331334333 and parameters: {'model_name_CNN': 'CNN', 'layer': 2, 'unit': 6, 'activation': 'Sigmoid', 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:40:16,852] Trial 78 finished with value: 0.664167916041979 and parameters: {'model_name_CNN': 'CNN', 'layer': 3, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:41:35,144] Trial 79 finished with value: 0.7038980509745127 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:42:54,008] Trial 80 finished with value: 0.6964017991004497 and parameters: {'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:45:17,378] Trial 81 finished with value: 0.4715142428785607 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 500, 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:46:57,117] Trial 82 finished with value: 0.43928035982008995 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 50, 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:48:37,813] Trial 83 finished with value: 0.4460269865067466 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 100, 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:50:17,272] Trial 84 finished with value: 0.4340329835082459 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 10, 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:51:55,919] Trial 85 finished with value: 0.43928035982008995 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 10, 'optimizer_select': 'SGD'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:54:18,787] Trial 86 finished with value: 0.44227886056971516 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 500, 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:55:58,448] Trial 87 finished with value: 0.45652173913043476 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 100, 'optimizer_select': 'Adam'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:57:37,837] Trial 88 finished with value: 0.44152923538230887 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 50, 'optimizer_select': 'RMSprop'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 09:59:17,865] Trial 89 finished with value: 0.4325337331334333 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 10, 'optimizer_select': 'SGD'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 10:01:40,921] Trial 90 finished with value: 0.46851574212893554 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 500, 'optimizer_select': 'RMSprop'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 10:03:21,145] Trial 91 finished with value: 0.44152923538230887 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 100, 'optimizer_select': 'RMSprop'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 10:05:00,866] Trial 92 finished with value: 0.4370314842578711 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 50, 'optimizer_select': 'RMSprop'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 10:06:40,191] Trial 93 finished with value: 0.43478260869565216 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 10, 'optimizer_select': 'RMSprop'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 10:08:19,811] Trial 94 finished with value: 0.4407796101949025 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 100, 'optimizer_select': 'RMSprop'}. Best is trial 74 with value: 0.7263868065967016.\n","[I 2024-06-23 10:10:42,698] Trial 95 finished with value: 0.4490254872563718 and parameters: {'model_name_LSTM': 'LSTM', 'HIDDEN_SIZE': 500, 'optimizer_select': 'RMSprop'}. Best is trial 74 with value: 0.7263868065967016.\n"]},{"output_type":"stream","name":"stdout","text":["{'model_name_CNN': 'CNN', 'layer': 1, 'unit': 6, 'activation': 'Tanh', 'optimizer_select': 'Adam'}\n","0.7263868065967016\n"]}]},{"cell_type":"code","source":["# 89\n","# Bertを使う\n","\n","%%bash\n","pip install transformers -q"],"metadata":{"id":"unPojUtl0fYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter\n","import torch.nn as nn\n","import numpy as np\n","import torch"],"metadata":{"id":"6q2p8_A81RAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 89\n","\n","class Bert(nn.Module):\n","  def __init__(self):\n","      super().__init__()\n","\n","      # 事前訓練済みBERTモデルをロードする\n","      self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n","\n","      # 768次元->4次元\n","      self.classifier = nn.Linear(in_features = 768, out_features = 4)\n","\n","\n","  def forward(self, input_ids, attention_mask, token_type_ids):\n","      outputs = self.bert(input_ids = input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids)\n","\n","      # pooling\n","      pooler_output = outputs.pooler_output\n","      logits = self.classifier(pooler_output).squeeze(-1)\n","      return logits\n","\n","\n","# Bert modelの利用ため、datasetを改造する\n","class BertDataset(Dataset):\n","  def __init__(self, data, label):\n","      super().__init__()\n","\n","      #　dataの長さ\n","      self.data_length = len(data[\"input_ids\"])\n","\n","      # 入力したdata\n","      self.x_input_ids = data[\"input_ids\"]\n","\n","      # 異なる文を区別するために使用される\n","      self.x_token_type_ids = data[\"token_type_ids\"]\n","\n","      # どのtokenが実際の入力の一部であり、どのtokenがpadding部分であるかを示すために使用される\n","      self.x_attention_mask = data[\"attention_mask\"]\n","\n","      # labelをもらう\n","      self.y = label\n","\n","  def __len__(self):\n","      return self.data_length\n","  def __getitem__(self, idx):\n","      # idx番目のデータを取得する\n","      x_input_ids = torch.tensor(self.x_input_ids[idx])\n","      x_token_type_ids = torch.tensor(self.x_token_type_ids[idx])\n","      x_attention_mask = torch.tensor(self.x_attention_mask[idx])\n","      return {\"input_ids\":x_input_ids, \"token_type_ids\":x_token_type_ids, \"x_attention_mask\":x_attention_mask}, torch.tensor(self.y[idx])\n","\n","# loss　と　正解率を計算する\n","def calculate_loss_and_accuracy(model, dataset, device, criterion=None):\n","    dataloader = DataLoader(dataset, batch_size=256, shuffle=False)\n","    loss = 0.0\n","    total = 0\n","    correct = 0\n","    model = model.to(device)\n","    with torch.no_grad():\n","      for X, Y in dataloader:\n","          input_ids = X[\"input_ids\"].to(device)\n","          attention_mask = X[\"x_attention_mask\"].to(device)\n","          token_type_ids = X[\"token_type_ids\"].to(device)\n","          Y = Y.to(device)\n","          Y_pred =  model(input_ids, attention_mask, token_type_ids)\n","          if criterion != None:\n","              loss += criterion(Y_pred, Y).item()\n","          pred = torch.argmax(Y_pred, dim=-1)\n","          total += len(Y)\n","          correct += (pred == Y).sum().item()\n","    return loss / len(dataset), correct / total\n","\n","# model を訓練する\n","def train_model(X_train, y_train, X_test, y_test, batch_size, model, lr, num_epochs, device, collate_fn=None):\n","\n","    dataset_train = BertDataset(X_train, y_train)\n","    dataset_test = BertDataset(X_test, y_test)\n","    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n","    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n","\n","    model = model.to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    criterion = criterion.to(device)\n","\n","    for ep in range(num_epochs):\n","        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","        model.train()\n","        if ep%30==0:\n","            lr = lr * 0.1\n","        for X, Y in dataloader_train:\n","            input_ids = X[\"input_ids\"].to(device)\n","            attention_mask = X[\"x_attention_mask\"].to(device)\n","            token_type_ids = X[\"token_type_ids\"].to(device)\n","\n","            Y = Y.to(device)\n","            optimizer.zero_grad()\n","            Y_pred = model(input_ids, attention_mask, token_type_ids)\n","            loss = criterion(Y_pred, Y)\n","            loss.backward()\n","            optimizer.step()\n","\n","        model.eval()\n","\n","        loss_train, acc_train = calculate_loss_and_accuracy(model, dataset_train, device, criterion=criterion)\n","        loss_test, acc_test = calculate_loss_and_accuracy(model, dataset_test, device, criterion=criterion)\n","\n","        print(f'epoch: {ep + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_Test: {loss_test:.4f}, accuracy_Test: {acc_test:.4f}')\n","\n","\n","# title と　CATEGORYのcodeをもらう\n","def GetStrLow(name):\n","    f = open(PATH + \"{}_code.txt\".format(name), \"r\")\n","    lines = f.readlines()\n","    f.close()\n","    sent_list = []\n","    code_list = []\n","\n","    for line in lines:\n","\n","      try:\n","        line_s = line.split(\"\\t\")\n","        code_list.append(int(line_s[0]))\n","        sent = line_s[1].replace(\"\\n\", \"\")\n","        sent_list.append(sent)\n","      except:\n","        pass\n","\n","    code_list = torch.tensor(code_list)\n","    return sent_list, code_list\n","\n","X_train, Y_train = GetStrLow(\"train\")\n","X_test, Y_test = GetStrLow(\"test\")\n","\n","MAX_LENGTH = 32\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","X_train_tokenizer = tokenizer.batch_encode_plus(X_train, padding = \"max_length\", max_length = MAX_LENGTH, truncation=True)\n","X_test_tokenizer = tokenizer.batch_encode_plus(X_test, padding = \"max_length\", max_length = MAX_LENGTH, truncation=True)\n","\n","BATCH_SIZE = 8\n","NUM_EPOCHS = 20\n","lr = 1e-3\n","\n","model = Bert()\n","train_model(X_train_tokenizer, Y_train, X_test_tokenizer, Y_test, BATCH_SIZE, model, lr, NUM_EPOCHS, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWPCQUF21MJd","executionInfo":{"status":"ok","timestamp":1719211820731,"user_tz":-540,"elapsed":1319552,"user":{"displayName":"Moon Air","userId":"01277311785671261049"}},"outputId":"fe51c961-8472-4eaf-fe80-7ee7fbbe7430"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-15-9188648c21a4>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return {\"input_ids\":x_input_ids, \"token_type_ids\":x_token_type_ids, \"x_attention_mask\":x_attention_mask}, torch.tensor(self.y[idx])\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 0.0010, accuracy_train: 0.9190, loss_Test: 0.0013, accuracy_Test: 0.9085\n","epoch: 2, loss_train: 0.0009, accuracy_train: 0.9263, loss_Test: 0.0012, accuracy_Test: 0.9130\n","epoch: 3, loss_train: 0.0009, accuracy_train: 0.9317, loss_Test: 0.0012, accuracy_Test: 0.9175\n","epoch: 4, loss_train: 0.0008, accuracy_train: 0.9346, loss_Test: 0.0011, accuracy_Test: 0.9220\n","epoch: 5, loss_train: 0.0008, accuracy_train: 0.9376, loss_Test: 0.0011, accuracy_Test: 0.9213\n","epoch: 6, loss_train: 0.0007, accuracy_train: 0.9403, loss_Test: 0.0011, accuracy_Test: 0.9235\n","epoch: 7, loss_train: 0.0007, accuracy_train: 0.9397, loss_Test: 0.0011, accuracy_Test: 0.9258\n","epoch: 8, loss_train: 0.0007, accuracy_train: 0.9454, loss_Test: 0.0011, accuracy_Test: 0.9273\n","epoch: 9, loss_train: 0.0007, accuracy_train: 0.9477, loss_Test: 0.0011, accuracy_Test: 0.9228\n","epoch: 10, loss_train: 0.0006, accuracy_train: 0.9499, loss_Test: 0.0011, accuracy_Test: 0.9295\n","epoch: 11, loss_train: 0.0006, accuracy_train: 0.9506, loss_Test: 0.0011, accuracy_Test: 0.9280\n","epoch: 12, loss_train: 0.0006, accuracy_train: 0.9548, loss_Test: 0.0010, accuracy_Test: 0.9303\n","epoch: 13, loss_train: 0.0006, accuracy_train: 0.9561, loss_Test: 0.0010, accuracy_Test: 0.9280\n","epoch: 14, loss_train: 0.0005, accuracy_train: 0.9569, loss_Test: 0.0010, accuracy_Test: 0.9318\n","epoch: 15, loss_train: 0.0005, accuracy_train: 0.9589, loss_Test: 0.0010, accuracy_Test: 0.9303\n","epoch: 16, loss_train: 0.0005, accuracy_train: 0.9612, loss_Test: 0.0010, accuracy_Test: 0.9325\n","epoch: 17, loss_train: 0.0005, accuracy_train: 0.9631, loss_Test: 0.0010, accuracy_Test: 0.9310\n","epoch: 18, loss_train: 0.0005, accuracy_train: 0.9639, loss_Test: 0.0010, accuracy_Test: 0.9295\n","epoch: 19, loss_train: 0.0004, accuracy_train: 0.9641, loss_Test: 0.0010, accuracy_Test: 0.9355\n","epoch: 20, loss_train: 0.0004, accuracy_train: 0.9672, loss_Test: 0.0010, accuracy_Test: 0.9318\n"]}]}]}